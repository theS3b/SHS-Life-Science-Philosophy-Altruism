{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 1, 5, 5]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_populations = 3\n",
    "\n",
    "# Seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Random mask\n",
    "empty_cells = torch.randint(0, 2, (2, number_of_populations, 5, 5), dtype=torch.bool).all(dim=1, keepdim=True)\n",
    "\n",
    "grid = torch.randn(2, number_of_populations, 5, 5)\n",
    "grid = grid.masked_fill(empty_cells, 0)  # Mask out empty cells\n",
    "\n",
    "# Define the kernel (same for all channels)\n",
    "kernel = torch.tensor([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=torch.float32)\n",
    "kernel = kernel / kernel.sum()  # Normalize kernel\n",
    "\n",
    "# Duplicate kernel for each channel: [out_channels=3, in_channels/groups=1, kH, kW]\n",
    "kernel = kernel.view(1, 1, 3, 3).repeat(number_of_populations, 1, 1, 1)  # shape: [3,1,3,3]\n",
    "\n",
    "# Pad input\n",
    "grid_padded = nn.CircularPad2d(1)(grid)  # Pad with reflection to avoid border issues\n",
    "\n",
    "# Apply depthwise convolution: groups = number of channels\n",
    "new_fitness = torch.nn.functional.conv2d(grid_padded, kernel, stride=1, padding=0, groups=grid.shape[1])\n",
    "\n",
    "new_fitness.shape, empty_cells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cells_expanded = empty_cells.expand(-1, number_of_populations, -1, -1)\n",
    "\n",
    "# Set fitness to 0 where the cell is not empty\n",
    "new_fitness[~empty_cells_expanded] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vals, max_indices = torch.max(new_fitness, dim=1, keepdim=True)\n",
    "\n",
    "# Step 2: Create a mask that is True where the max occurs\n",
    "mask = torch.arange(new_fitness.size(1), device=new_fitness.device).view(1, -1, 1, 1) == max_indices\n",
    "\n",
    "# Step 3: Zero out everything that's not the max\n",
    "result = new_fitness * mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2011,  0.0000,  0.0000, -1.4073,  1.6268],\n",
       "         [ 0.1723, -1.6115, -0.4794,  0.1574,  0.0000],\n",
       "         [ 0.0000,  0.9979,  0.5436,  0.0788,  0.8629],\n",
       "         [-0.0195,  0.7611,  0.6183, -0.2994, -0.1878],\n",
       "         [ 1.9159,  0.0000, -2.3217, -1.1964,  0.2408]],\n",
       "\n",
       "        [[-1.3962,  0.0000,  0.0000, -1.3952,  0.4751],\n",
       "         [-0.8137,  0.9242,  1.5735,  0.7814,  0.0000],\n",
       "         [ 0.0000,  0.5867,  0.1583,  0.1102, -0.8188],\n",
       "         [-1.1894, -1.1959,  1.3119, -0.2098,  0.7817],\n",
       "         [ 0.9897,  0.0000, -1.5090, -0.2871,  1.0216]],\n",
       "\n",
       "        [[-0.5111,  0.0000,  0.0000, -0.4749, -0.6334],\n",
       "         [-1.4677,  0.6074, -0.5472, -1.1005,  0.0000],\n",
       "         [ 0.0000,  0.3398, -0.2635,  1.2805, -0.4947],\n",
       "         [-1.2830,  0.4386, -0.0107,  1.3384, -0.2794],\n",
       "         [-0.5518,  0.0000, -1.0619, -0.1144,  0.1954]]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update grid\n",
    "new_grid = grid + result\n",
    "grid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 8 directional kernels for 10% value shift\n",
    "kernels = torch.zeros((8, 1, 3, 3), dtype=torch.float32)\n",
    "offsets = torch.tensor([\n",
    "    [1,  0],  # 1: up\n",
    "    [1,  1],  # 2: up-right\n",
    "    [0,  1],  # 3: right\n",
    "    [-1,  1],  # 4: down-right\n",
    "    [-1,  0],  # 5: down\n",
    "    [-1, -1],  # 6: down-left\n",
    "    [ 0, -1],  # 7: left\n",
    "    [1, -1],  # 8: up-left\n",
    "], dtype=torch.long)\n",
    "\n",
    "for i, (dy, dx) in enumerate(offsets):\n",
    "    kernel = torch.zeros((1, 3, 3), dtype=torch.float32)\n",
    "    kernel[0, 1 + dy, 1 + dx] = 0.1  # Set the offset value to 0.1\n",
    "    kernels[i] = kernel\n",
    "\n",
    "action = torch.randint(1, 9, (2, 1, 5, 5), device=grid.device)  # Random action for each population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume grid has shape (batch, nb_pop, n, m) and we take max over nb_pop:\n",
    "max_vals, max_indices = torch.max(grid, dim=1, keepdim=True)  # shape: (batch, 1, n, m)\n",
    "\n",
    "# Create a one-hot action mask from max_indices (actions assumed in 1-8)\n",
    "action_mask = F.one_hot((max_indices.squeeze(1)), num_classes=8)  # shape: (batch, n, m, 8)\n",
    "action_mask = action_mask.permute(0, 3, 1, 2).float()  # shape: (batch, 8, n, m)\n",
    "\n",
    "# Pad max_vals (single channel) using reflection padding\n",
    "max_vals_padded = nn.CircularPad2d(1)(max_vals)  # shape: (batch, 1, n+2, m+2)\n",
    "\n",
    "# 'kernels' should be defined as before with shape (8, 1, 3, 3)\n",
    "# Perform convolution: input has 1 channel, kernels have 1 input channel, output 8 channels\n",
    "new_vals = F.conv2d(max_vals_padded, kernels, stride=1, padding=0)  # shape: (batch, 8, n, m)\n",
    "\n",
    "# Select contributions using the action mask: keep only the kernel corresponding to each cell's action\n",
    "new_vals_masked = new_vals * action_mask\n",
    "\n",
    "# Sum over the 8 directional contributions for each cell\n",
    "new_vals_sum = new_vals_masked.sum(dim=1, keepdim=True)  # shape: (batch, 1, n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: up, 2: up-right, 3: right, 4: down-right, 5: down, 6: down-left, 7: left, 8: up-left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_action = action - 1\n",
    "up = torch.roll(torch.where(shifted_action == 0, max_vals, 0), shifts=-1, dims=2)\n",
    "up_right = torch.roll(torch.where(shifted_action == 1, max_vals, 0), shifts=(-1, 1), dims=(2, 3))\n",
    "right = torch.roll(torch.where(shifted_action == 2, max_vals, 0), shifts=1, dims=3)\n",
    "down_right = torch.roll(torch.where(shifted_action == 3, max_vals, 0), shifts=(1, 1), dims=(2, 3))\n",
    "down = torch.roll(torch.where(shifted_action == 4, max_vals, 0), shifts=1, dims=2)\n",
    "down_left = torch.roll(torch.where(shifted_action == 5, max_vals, 0), shifts=(1, -1), dims=(2, 3))\n",
    "left = torch.roll(torch.where(shifted_action == 6, max_vals, 0), shifts=-1, dims=3)\n",
    "up_left = torch.roll(torch.where(shifted_action == 7, max_vals, 0), shifts=(-1, -1), dims=(2, 3))\n",
    "\n",
    "# Combine all contributions\n",
    "contributions = up + up_right + right + down_right + down + down_left + left + up_left\n",
    "\n",
    "new_grid = 0.1 * contributions  # Update grid with 10% of the contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2011,  0.0000,  0.0000, -0.4749,  1.6268],\n",
       "         [ 0.1723,  0.9242,  1.5735,  0.7814,  0.0000],\n",
       "         [ 0.0000,  0.9979,  0.5436,  1.2805,  0.8629],\n",
       "         [-0.0195,  0.7611,  1.3119,  1.3384,  0.7817],\n",
       "         [ 1.9159,  0.0000, -1.0619, -0.1144,  1.0216]]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6, 5, 3, 6, 4],\n",
       "         [7, 5, 2, 4, 6],\n",
       "         [5, 2, 1, 4, 0],\n",
       "         [1, 0, 2, 0, 3],\n",
       "         [5, 2, 0, 2, 3]]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_action[0]\n",
    "# 0: up, 1: up-right, 2: right, 3: down-right, 4: down, 5: down-left, 6: left, 7: up-left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2011,  0.0000,  0.0000, -0.4749,  1.6268],\n",
       "         [ 0.1723,  0.9242,  1.5735,  0.7814,  0.0000],\n",
       "         [ 0.0000,  0.9979,  0.5436,  1.2805,  0.8629],\n",
       "         [-0.0195,  0.7611,  1.3119,  1.3384,  0.7817],\n",
       "         [ 1.9159,  0.0000, -1.0619, -0.1144,  1.0216]]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.8629],\n",
       "         [ 0.0000,  0.7611,  0.0000,  1.3384,  0.0000],\n",
       "         [ 0.0000,  0.0000, -1.0619,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "action_grid = torch.randint(9, 17, (2, 1, 5, 5))\n",
    "grid = torch.randn(2, 3, 5, 5)\n",
    "\n",
    "flat_grid, _ = torch.max(grid, dim=1, keepdim=True)  # shape: (batch, 1, n, m)\n",
    "initial_flat_grid = flat_grid.clone()  # Store the initial state for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0],\n",
       "         [ 0,  0, 16,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0]]])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_grid = torch.zeros_like(action_grid)\n",
    "action_grid[0, 0, 3, 2] = 8 + 8\n",
    "action_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directional index (0 to 7) for attack actions:\n",
    "shifted_action = (action_grid - 9)\n",
    "\n",
    "# Initialize bonus accumulator (same shape as flat_grid: [batch, 1, rows, cols])\n",
    "bonus = torch.zeros_like(flat_grid)\n",
    "\n",
    "empty_cells = (flat_grid <= 1e-6).all(dim=1)  # shape: [batch, rows, cols]\n",
    "\n",
    "circ_kernel = torch.tensor([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=flat_grid.dtype, device=flat_grid.device).view(1, 1, 3, 3)\n",
    "nb_existing_neighbors = torch.nn.functional.conv2d(\n",
    "    nn.CircularPad2d(1)((~empty_cells).float()).unsqueeze(1),\n",
    "    circ_kernel\n",
    ")\n",
    "\n",
    "# Define the 8 directional shifts (row, col) corresponding to neighbors:\n",
    "# 0: up, 1: up-right, 2: right, 3: down-right,\n",
    "# 4: down, 5: down-left, 6: left, 7: up-left.\n",
    "shifts = [(-1, 0), (-1, 1), (0, 1), (1, 1),\n",
    "        (1, 0), (1, -1), (0, -1), (-1, -1)]\n",
    "\n",
    "# Process each direction separately\n",
    "for i, (shift_row, shift_col) in enumerate(shifts):\n",
    "    # Create mask for cells whose shifted_action equals this direction (attack events)\n",
    "    mask = (shifted_action == i)\n",
    "    if mask.sum() == 0:\n",
    "        continue  # No attack events in this direction\n",
    "    \n",
    "    # Get attacker values from flat_grid where attack occurs.\n",
    "    attacker_vals = torch.where(mask, flat_grid, torch.zeros_like(flat_grid))\n",
    "\n",
    "    # Get defender values from the neighbor cell by rolling the flat_grid.\n",
    "    defender_mapped_to_attacker_vals = torch.roll(flat_grid, shifts=(-shift_row, -shift_col), dims=(2, 3))\n",
    "    defender_mapped_to_attacker_vals = torch.where(mask, defender_mapped_to_attacker_vals, torch.zeros_like(flat_grid))\n",
    "    \n",
    "    # Compute the value to subtract: the minimum of the two values.\n",
    "    vals = torch.min(attacker_vals, defender_mapped_to_attacker_vals)\n",
    "    \n",
    "    # Subtract val from the attacker cell.\n",
    "    flat_grid = torch.where(mask, flat_grid - vals, flat_grid)\n",
    "\n",
    "    # For the defender, roll the mask to align with neighbor positions.\n",
    "    defender_mask = torch.roll(mask, shifts=(shift_row, shift_col), dims=(2, 3))\n",
    "    vals_mapped_to_defender = torch.roll(vals, shifts=(shift_row, shift_col), dims=(2, 3))\n",
    "    flat_grid = torch.where(defender_mask, flat_grid - vals_mapped_to_defender, flat_grid)\n",
    "\n",
    "    attacker_dying_cells = (flat_grid <= 1e-6) & mask\n",
    "    defender_dying_cells = (flat_grid <= 1e-6) & defender_mask\n",
    "\n",
    "    bonus = torch.zeros_like(flat_grid)  # Reset bonus for each direction\n",
    "    bonus[attacker_dying_cells] = vals[attacker_dying_cells]  # Assign bonus to dying cells\n",
    "    bonus[defender_dying_cells] = vals_mapped_to_defender[defender_dying_cells]  # Assign bonus to dying cells\n",
    "\n",
    "    bonus = bonus / nb_existing_neighbors.clamp(min=1e-6)  # Avoid division by zero\n",
    "\n",
    "    # Distribute bonus using convolution with circular padding.\n",
    "    distributed_bonus = torch.nn.functional.conv2d(\n",
    "        torch.nn.functional.pad(bonus, (1, 1, 1, 1), mode='circular'),\n",
    "        circ_kernel\n",
    "    )\n",
    "\n",
    "    # Remove bonus from empty cells\n",
    "    distributed_bonus[empty_cells.unsqueeze(1)] = 0\n",
    "    # flat_grid += distributed_bonus  # Update flat_grid with distributed bonus\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0554e+00,  1.7784e-01,  1.1149e+00,  2.7995e-01,  8.0575e-01],\n",
       "         [ 1.1133e+00,  3.3801e-01,  4.5440e-01,  1.5210e+00,  3.4105e+00],\n",
       "         [ 7.8131e-01,  1.0395e+00,  1.8197e+00, -3.3039e-03, -7.2915e-02],\n",
       "         [ 1.8855e-01,  1.1108e+00,  1.2899e+00, -9.2146e-01,  2.5672e+00],\n",
       "         [ 7.1009e-01,  1.0367e+00,  1.9218e+00,  2.0820e+00,  5.1987e-01]]])"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_flat_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0554e+00,  1.7784e-01,  1.1149e+00,  2.7995e-01,  8.0575e-01],\n",
       "         [ 1.1133e+00,  3.3801e-01,  4.5440e-01,  1.5210e+00,  3.4105e+00],\n",
       "         [ 7.8131e-01,  0.0000e+00,  1.8197e+00, -3.3039e-03, -7.2915e-02],\n",
       "         [ 1.8855e-01,  1.1108e+00,  2.5041e-01, -9.2146e-01,  2.5672e+00],\n",
       "         [ 7.1009e-01,  1.0367e+00,  1.9218e+00,  2.0820e+00,  5.1987e-01]]])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1299, 0.1299, 0.1299, 0.0000, 0.0000],\n",
       "         [0.1299, 0.0000, 0.1299, 0.0000, 0.0000],\n",
       "         [0.1299, 0.1299, 0.1299, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_bonus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
